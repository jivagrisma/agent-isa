# Configuración del módulo Core

[general]
debug = false
log_level = "INFO"

[plugin_manager]
auto_discover = true
auto_load = true

[llm]
api_type = "bedrock"  # "openai", "azure", "bedrock"
model_id = "anthropic.claude-3-sonnet-20240229-v1:0"
region = "us-east-1"

# Configuración específica para cada proveedor
[llm.providers.bedrock]
temperature = 0.7
max_tokens = 4096
top_p = 0.9

[llm.providers.openai]
api_key = ""
base_url = "https://api.openai.com/v1"
model = "gpt-4"
temperature = 0.7
max_tokens = 4096

[llm.providers.azure]
api_key = ""
base_url = ""
api_version = "2023-05-15"
deployment_name = "gpt-4"
temperature = 0.7
max_tokens = 4096

[web_interface]
host = "0.0.0.0"
port = 8005
debug = false
title = "ISA-Agent Chat"
welcome_message = "¡Hola! Soy el asistente ISA. ¿En qué puedo ayudarte hoy?"
